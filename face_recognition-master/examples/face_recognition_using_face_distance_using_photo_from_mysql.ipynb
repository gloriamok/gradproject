{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jukyuknam nam\n",
      "yoojungkim kim\n",
      "suzibae bae\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pymysql\n",
    "\n",
    "# MySQL 연결 - DB server에 연결, 정상적으로 연결이 수립되면 커넥션 객체를 반환\n",
    "#conn = pymysql.connect(host='localhost', user='root', password='1234', db='encore', charset='utf8')\n",
    "conn = pymysql.connect(host='localhost', user='sptest', password='sptest', db='testdb', charset='utf8')\n",
    "# 커서 생성 - 커넥션 객체를 통해 데이터베이스에서 SQL문을 대신 실행해주고 결과를 반환해 줄 커서 객체를 생성한다.\n",
    "cur = conn.cursor()\n",
    "# 데이터 조회 - 커서에 SELECT로 조회한 결과를 한꺼번에 저장\n",
    "# sql = 'select * from departments where department_id=%d'\n",
    "# vals = (department_id,)\n",
    "# cur.execute(sql, vals)\n",
    "sql = \"select * from USER\"\n",
    "cur.execute(sql)\n",
    "\n",
    "# 조회결과를 커서에서 fetch - 조회한 데이터를 커서객체에서 한 행씩 접근하여 출력\n",
    "#여러 줄 출력\n",
    "for row in cur:\n",
    "\t\tprint(row[0], row[1])\n",
    "\n",
    "#한 줄 출력\n",
    "# row = cur.fetchone()\n",
    "# if row == None:\n",
    "#     print('검색결과없음')\n",
    "# else:\n",
    "#     print(row[0], row[1], row[2], row[3])\n",
    "\n",
    "\n",
    "##### MySQL에 이미지 저장\n",
    "import base64\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yoojungkim\n"
     ]
    }
   ],
   "source": [
    "# 얼굴인식한 사람이 입력한 아이디를 가져옴\n",
    "sql = \"select * from FACE\"\n",
    "cur.execute(sql)\n",
    "row = cur.fetchone()\n",
    "unknownId = row[0]\n",
    "print(unknownId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_2\n",
      "['person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2', 'person_2']\n"
     ]
    }
   ],
   "source": [
    "# 이미 db에 저장되어있는 사진과\n",
    "# 얼굴인식한 사람이 입력한 아이디의 사진과 비교\n",
    "# 이미 db에 저장되어있는 사진들은 각각 encoding이 완료된 상태여야 함***\n",
    "userId_dict = {\"jukyuknam\":\"person_1\", \"yoojungkim\":\"person_2\", \"suzibae\":\"person_3\", \"bogumpark\":\"person_4\"}\n",
    "person_to_compare = userId_dict[unknownId]\n",
    "print(person_to_compare)\n",
    "\n",
    "# The training data would be all the face encodings from all the known images and the labels are their names\n",
    "encodings = []\n",
    "names = []\n",
    "\n",
    "# Loop through each person in the training directory\n",
    "pix = os.listdir(\"train_dir/\" + person_to_compare)\n",
    "\n",
    "# Loop through each training image for the current person\n",
    "for person_img in pix:\n",
    "    # Get the face encodings for the face in each image file\n",
    "    face = face_recognition.load_image_file(\"train_dir/\" + person_to_compare + \"/\" + person_img)\n",
    "    face_bounding_boxes = face_recognition.face_locations(face)\n",
    "\n",
    "    #If training image contains exactly one face\n",
    "    if len(face_bounding_boxes) == 1:\n",
    "        face_enc = face_recognition.face_encodings(face)[0]\n",
    "        # Add face encoding for current image with corresponding label (name) to the training data\n",
    "        encodings.append(face_enc)\n",
    "        names.append(person_to_compare)\n",
    "    else:\n",
    "        print(\"train_dir/\" + person_img + \" was skipped and can't be used for training\")\n",
    "            \n",
    "            \n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'JpegImageFile' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e83564fbefd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0munknown_Image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretriveImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munknownId\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#convert a PIL Image into a NumPy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-e83564fbefd3>\u001b[0m in \u001b[0;36mretriveImage\u001b[1;34m(userId)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Convert the bytes into a PIL image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Display the image using default image app\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#image.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'JpegImageFile' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "#얼굴인식한 사진을 mysql에서 갖고 옴\n",
    "def retriveImage(userId):\n",
    "    sql = \"SELECT userFace FROM FACE WHERE userId=%s\"\n",
    "    cur.execute(sql, (userId,))\n",
    "    results = cur.fetchall()\n",
    "    # the returned data will be a list of list\n",
    "    image = results[0][0]\n",
    "    # Decode the string\n",
    "    binary_data = base64.b64decode(image)\n",
    "    # Convert the bytes into a PIL image\n",
    "    image = Image.open(io.BytesIO(binary_data))\n",
    "    image.type\n",
    "    # Display the image using default image app\n",
    "    #image.show()\n",
    "    return image\n",
    "\n",
    "unknown_Image = retriveImage(unknownId)\n",
    "\n",
    "#convert a PIL Image into a NumPy array\n",
    "unknown_Image2 = np.array(unknown_Image)\n",
    "\n",
    "\n",
    "# 얼굴인식 사진을 person_to_compare로 인코딩한 사진들과 비교\n",
    "def face_recognition_result(image_to_test):\n",
    "    image_to_test_encoding = face_recognition.face_encodings(image_to_test)[0]\n",
    "\n",
    "    # See how far apart the test image is from the known faces\n",
    "    face_distances = face_recognition.face_distance(encodings, image_to_test_encoding)\n",
    "\n",
    "    total=0\n",
    "\n",
    "    for i, face_distance in enumerate(face_distances):\n",
    "        # print(\"The test image has a distance of {:.2} from known image #{}\".format(face_distance, i))\n",
    "        total += face_distance\n",
    "        # print()\n",
    "\n",
    "    print(total/20)\n",
    "    print(1 - total/20)\n",
    "    \n",
    "    if (total/20 < 0.40):\n",
    "        print(unknownId + \" TRUE\")\n",
    "    else:\n",
    "        print(unknownId + \" FALSE\")\n",
    "\n",
    "face_recognition_result(unknown_Image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
